{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMaxScaler(copy=True, feature_range=(0, 1))\n",
      "MinMaxScaler(copy=True, feature_range=(0, 1))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "dataset =pd.read_csv('cars.csv')\n",
    "\n",
    "X = dataset.iloc[:,0:5]\n",
    "Y = dataset.iloc[:,5]\n",
    "\n",
    "Y = Y[:,np.newaxis]\n",
    "\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_Y = MinMaxScaler()\n",
    "\n",
    "print(scaler_X.fit(X))\n",
    "xscale=scaler_X.transform(X)\n",
    "\n",
    "print(scaler_Y.fit(Y))\n",
    "yscale=scaler_Y.transform(Y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(xscale, yscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 12)                72        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 185\n",
      "Trainable params: 185\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12,input_dim = 5,kernel_initializer='normal',activation='relu'))\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='linear'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 577 samples, validate on 145 samples\n",
      "Epoch 1/150\n",
      "577/577 [==============================] - 0s 604us/sample - loss: 0.2383 - mse: 0.2383 - val_loss: 0.2096 - val_mse: 0.2096\n",
      "Epoch 2/150\n",
      "577/577 [==============================] - 0s 40us/sample - loss: 0.2108 - mse: 0.2108 - val_loss: 0.1875 - val_mse: 0.1875\n",
      "Epoch 3/150\n",
      "577/577 [==============================] - 0s 45us/sample - loss: 0.1881 - mse: 0.1881 - val_loss: 0.1684 - val_mse: 0.1684\n",
      "Epoch 4/150\n",
      "577/577 [==============================] - 0s 45us/sample - loss: 0.1676 - mse: 0.1676 - val_loss: 0.1509 - val_mse: 0.1509\n",
      "Epoch 5/150\n",
      "577/577 [==============================] - 0s 42us/sample - loss: 0.1493 - mse: 0.1493 - val_loss: 0.1346 - val_mse: 0.1346\n",
      "Epoch 6/150\n",
      "577/577 [==============================] - 0s 43us/sample - loss: 0.1308 - mse: 0.1308 - val_loss: 0.1189 - val_mse: 0.1189\n",
      "Epoch 7/150\n",
      "577/577 [==============================] - 0s 43us/sample - loss: 0.1138 - mse: 0.1138 - val_loss: 0.1047 - val_mse: 0.1047\n",
      "Epoch 8/150\n",
      "577/577 [==============================] - 0s 38us/sample - loss: 0.0978 - mse: 0.0978 - val_loss: 0.0931 - val_mse: 0.0931\n",
      "Epoch 9/150\n",
      "577/577 [==============================] - 0s 43us/sample - loss: 0.0852 - mse: 0.0852 - val_loss: 0.0855 - val_mse: 0.0855\n",
      "Epoch 10/150\n",
      "577/577 [==============================] - 0s 40us/sample - loss: 0.0767 - mse: 0.0767 - val_loss: 0.0816 - val_mse: 0.0816\n",
      "Epoch 11/150\n",
      "577/577 [==============================] - 0s 41us/sample - loss: 0.0714 - mse: 0.0714 - val_loss: 0.0788 - val_mse: 0.0788\n",
      "Epoch 12/150\n",
      "577/577 [==============================] - 0s 40us/sample - loss: 0.0677 - mse: 0.0677 - val_loss: 0.0752 - val_mse: 0.0752\n",
      "Epoch 13/150\n",
      "577/577 [==============================] - 0s 39us/sample - loss: 0.0637 - mse: 0.0637 - val_loss: 0.0703 - val_mse: 0.0703\n",
      "Epoch 14/150\n",
      "577/577 [==============================] - 0s 46us/sample - loss: 0.0594 - mse: 0.0594 - val_loss: 0.0655 - val_mse: 0.0655\n",
      "Epoch 15/150\n",
      "577/577 [==============================] - 0s 40us/sample - loss: 0.0551 - mse: 0.0551 - val_loss: 0.0607 - val_mse: 0.0607\n",
      "Epoch 16/150\n",
      "577/577 [==============================] - 0s 40us/sample - loss: 0.0507 - mse: 0.0507 - val_loss: 0.0558 - val_mse: 0.0558\n",
      "Epoch 17/150\n",
      "577/577 [==============================] - 0s 42us/sample - loss: 0.0464 - mse: 0.0464 - val_loss: 0.0512 - val_mse: 0.0512\n",
      "Epoch 18/150\n",
      "577/577 [==============================] - 0s 45us/sample - loss: 0.0422 - mse: 0.0422 - val_loss: 0.0465 - val_mse: 0.0465\n",
      "Epoch 19/150\n",
      "577/577 [==============================] - 0s 40us/sample - loss: 0.0381 - mse: 0.0381 - val_loss: 0.0422 - val_mse: 0.0422\n",
      "Epoch 20/150\n",
      "577/577 [==============================] - 0s 42us/sample - loss: 0.0343 - mse: 0.0343 - val_loss: 0.0376 - val_mse: 0.0376\n",
      "Epoch 21/150\n",
      "577/577 [==============================] - 0s 40us/sample - loss: 0.0307 - mse: 0.0307 - val_loss: 0.0333 - val_mse: 0.0333\n",
      "Epoch 22/150\n",
      "577/577 [==============================] - 0s 45us/sample - loss: 0.0274 - mse: 0.0274 - val_loss: 0.0297 - val_mse: 0.0297\n",
      "Epoch 23/150\n",
      "577/577 [==============================] - 0s 43us/sample - loss: 0.0243 - mse: 0.0243 - val_loss: 0.0264 - val_mse: 0.0264\n",
      "Epoch 24/150\n",
      "577/577 [==============================] - 0s 43us/sample - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 25/150\n",
      "577/577 [==============================] - 0s 45us/sample - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0216 - val_mse: 0.0216\n",
      "Epoch 26/150\n",
      "577/577 [==============================] - 0s 42us/sample - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 27/150\n",
      "577/577 [==============================] - 0s 41us/sample - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 28/150\n",
      "577/577 [==============================] - 0s 39us/sample - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 29/150\n",
      "577/577 [==============================] - 0s 43us/sample - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 30/150\n",
      "577/577 [==============================] - 0s 41us/sample - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 31/150\n",
      "577/577 [==============================] - 0s 44us/sample - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 32/150\n",
      "577/577 [==============================] - 0s 39us/sample - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 33/150\n",
      "577/577 [==============================] - 0s 43us/sample - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 34/150\n",
      "577/577 [==============================] - 0s 42us/sample - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 35/150\n",
      "577/577 [==============================] - 0s 45us/sample - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 36/150\n",
      "577/577 [==============================] - 0s 43us/sample - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 37/150\n",
      "577/577 [==============================] - 0s 40us/sample - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 38/150\n",
      "577/577 [==============================] - 0s 44us/sample - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 39/150\n",
      "577/577 [==============================] - 0s 40us/sample - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 40/150\n",
      "577/577 [==============================] - 0s 47us/sample - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 41/150\n",
      "577/577 [==============================] - 0s 40us/sample - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 42/150\n",
      "577/577 [==============================] - 0s 43us/sample - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 43/150\n",
      "577/577 [==============================] - 0s 40us/sample - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 44/150\n",
      "577/577 [==============================] - 0s 40us/sample - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 45/150\n",
      "577/577 [==============================] - 0s 44us/sample - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 46/150\n",
      "577/577 [==============================] - 0s 43us/sample - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 47/150\n",
      "577/577 [==============================] - 0s 43us/sample - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 48/150\n",
      "577/577 [==============================] - 0s 42us/sample - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 49/150\n",
      "577/577 [==============================] - 0s 43us/sample - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 50/150\n",
      "577/577 [==============================] - 0s 42us/sample - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 51/150\n",
      "577/577 [==============================] - 0s 40us/sample - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 52/150\n",
      "577/577 [==============================] - 0s 42us/sample - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 53/150\n",
      "577/577 [==============================] - 0s 45us/sample - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 54/150\n",
      "577/577 [==============================] - 0s 45us/sample - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 55/150\n",
      "577/577 [==============================] - 0s 38us/sample - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 56/150\n",
      "577/577 [==============================] - 0s 40us/sample - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 57/150\n",
      "577/577 [==============================] - 0s 40us/sample - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 58/150\n",
      "577/577 [==============================] - 0s 41us/sample - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 59/150\n",
      "577/577 [==============================] - 0s 43us/sample - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 60/150\n",
      "577/577 [==============================] - 0s 42us/sample - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 61/150\n",
      "577/577 [==============================] - ETA: 0s - loss: 0.0145 - mse: 0.014 - 0s 42us/sample - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 62/150\n",
      "577/577 [==============================] - 0s 42us/sample - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 63/150\n",
      "577/577 [==============================] - 0s 42us/sample - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 64/150\n",
      "577/577 [==============================] - 0s 40us/sample - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 65/150\n",
      "577/577 [==============================] - 0s 40us/sample - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 66/150\n",
      "577/577 [==============================] - 0s 43us/sample - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 67/150\n",
      "577/577 [==============================] - 0s 43us/sample - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 68/150\n",
      "577/577 [==============================] - 0s 42us/sample - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 69/150\n",
      "577/577 [==============================] - 0s 43us/sample - loss: 0.0120 - mse: 0.0120 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 70/150\n",
      "577/577 [==============================] - 0s 42us/sample - loss: 0.0120 - mse: 0.0120 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 71/150\n",
      "577/577 [==============================] - 0s 40us/sample - loss: 0.0119 - mse: 0.0119 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 72/150\n",
      "577/577 [==============================] - 0s 40us/sample - loss: 0.0120 - mse: 0.0120 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 73/150\n",
      "577/577 [==============================] - 0s 43us/sample - loss: 0.0118 - mse: 0.0118 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 74/150\n",
      "577/577 [==============================] - 0s 42us/sample - loss: 0.0119 - mse: 0.0119 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 75/150\n",
      "577/577 [==============================] - 0s 43us/sample - loss: 0.0118 - mse: 0.0118 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 76/150\n",
      "577/577 [==============================] - 0s 42us/sample - loss: 0.0118 - mse: 0.0118 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 77/150\n",
      "577/577 [==============================] - 0s 40us/sample - loss: 0.0117 - mse: 0.0117 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 78/150\n",
      "577/577 [==============================] - 0s 42us/sample - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 79/150\n",
      "577/577 [==============================] - 0s 43us/sample - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 80/150\n",
      "577/577 [==============================] - 0s 42us/sample - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 81/150\n",
      "577/577 [==============================] - 0s 42us/sample - loss: 0.0115 - mse: 0.0115 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 82/150\n",
      "577/577 [==============================] - 0s 40us/sample - loss: 0.0115 - mse: 0.0115 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 83/150\n",
      "577/577 [==============================] - 0s 40us/sample - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 84/150\n",
      "577/577 [==============================] - 0s 40us/sample - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 85/150\n",
      "577/577 [==============================] - 0s 42us/sample - loss: 0.0113 - mse: 0.0113 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 86/150\n",
      "577/577 [==============================] - 0s 40us/sample - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 87/150\n",
      "577/577 [==============================] - 0s 40us/sample - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 88/150\n",
      "577/577 [==============================] - 0s 40us/sample - loss: 0.0113 - mse: 0.0113 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 89/150\n",
      "577/577 [==============================] - 0s 40us/sample - loss: 0.0113 - mse: 0.0113 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 90/150\n",
      "577/577 [==============================] - 0s 38us/sample - loss: 0.0112 - mse: 0.0112 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 91/150\n",
      "577/577 [==============================] - 0s 38us/sample - loss: 0.0112 - mse: 0.0112 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 92/150\n",
      "577/577 [==============================] - 0s 40us/sample - loss: 0.0111 - mse: 0.0111 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 93/150\n",
      "577/577 [==============================] - 0s 40us/sample - loss: 0.0111 - mse: 0.0111 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 94/150\n",
      "577/577 [==============================] - 0s 40us/sample - loss: 0.0111 - mse: 0.0111 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 95/150\n",
      "577/577 [==============================] - 0s 38us/sample - loss: 0.0111 - mse: 0.0111 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 96/150\n",
      "577/577 [==============================] - 0s 42us/sample - loss: 0.0111 - mse: 0.0111 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 97/150\n",
      "577/577 [==============================] - 0s 36us/sample - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 98/150\n",
      "577/577 [==============================] - 0s 39us/sample - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 99/150\n",
      "577/577 [==============================] - 0s 40us/sample - loss: 0.0109 - mse: 0.0109 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 100/150\n",
      "577/577 [==============================] - 0s 40us/sample - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 101/150\n",
      "577/577 [==============================] - 0s 43us/sample - loss: 0.0109 - mse: 0.0109 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 102/150\n",
      "577/577 [==============================] - 0s 43us/sample - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 103/150\n",
      "577/577 [==============================] - 0s 45us/sample - loss: 0.0109 - mse: 0.0109 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 104/150\n",
      "577/577 [==============================] - 0s 45us/sample - loss: 0.0109 - mse: 0.0109 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 105/150\n",
      "577/577 [==============================] - 0s 46us/sample - loss: 0.0109 - mse: 0.0109 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 106/150\n",
      "577/577 [==============================] - 0s 43us/sample - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 107/150\n",
      "577/577 [==============================] - 0s 42us/sample - loss: 0.0109 - mse: 0.0109 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 108/150\n",
      "577/577 [==============================] - 0s 42us/sample - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 109/150\n",
      "577/577 [==============================] - 0s 38us/sample - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 110/150\n",
      "577/577 [==============================] - 0s 39us/sample - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 111/150\n",
      "577/577 [==============================] - 0s 43us/sample - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 112/150\n",
      "577/577 [==============================] - 0s 40us/sample - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 113/150\n",
      "577/577 [==============================] - 0s 42us/sample - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 114/150\n",
      "577/577 [==============================] - 0s 38us/sample - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 115/150\n",
      "577/577 [==============================] - 0s 40us/sample - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 116/150\n",
      "577/577 [==============================] - 0s 42us/sample - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 117/150\n",
      "577/577 [==============================] - 0s 42us/sample - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 118/150\n",
      "577/577 [==============================] - 0s 43us/sample - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 119/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "577/577 [==============================] - 0s 43us/sample - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 120/150\n",
      "577/577 [==============================] - 0s 44us/sample - loss: 0.0106 - mse: 0.0106 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 121/150\n",
      "577/577 [==============================] - 0s 45us/sample - loss: 0.0106 - mse: 0.0106 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 122/150\n",
      "577/577 [==============================] - 0s 45us/sample - loss: 0.0106 - mse: 0.0106 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 123/150\n",
      "577/577 [==============================] - ETA: 0s - loss: 0.0216 - mse: 0.021 - 0s 40us/sample - loss: 0.0106 - mse: 0.0106 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 124/150\n",
      "577/577 [==============================] - 0s 40us/sample - loss: 0.0106 - mse: 0.0106 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 125/150\n",
      "577/577 [==============================] - 0s 40us/sample - loss: 0.0106 - mse: 0.0106 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 126/150\n",
      "577/577 [==============================] - 0s 38us/sample - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 127/150\n",
      "577/577 [==============================] - 0s 40us/sample - loss: 0.0106 - mse: 0.0106 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 128/150\n",
      "577/577 [==============================] - 0s 40us/sample - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 129/150\n",
      "577/577 [==============================] - 0s 42us/sample - loss: 0.0106 - mse: 0.0106 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 130/150\n",
      "577/577 [==============================] - 0s 42us/sample - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 131/150\n",
      "577/577 [==============================] - 0s 38us/sample - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 132/150\n",
      "577/577 [==============================] - 0s 40us/sample - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 133/150\n",
      "577/577 [==============================] - 0s 41us/sample - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 134/150\n",
      "577/577 [==============================] - 0s 40us/sample - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 135/150\n",
      "577/577 [==============================] - 0s 38us/sample - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 136/150\n",
      "577/577 [==============================] - 0s 43us/sample - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 137/150\n",
      "577/577 [==============================] - 0s 40us/sample - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 138/150\n",
      "577/577 [==============================] - 0s 40us/sample - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 139/150\n",
      "577/577 [==============================] - 0s 39us/sample - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 140/150\n",
      "577/577 [==============================] - 0s 40us/sample - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 141/150\n",
      "577/577 [==============================] - 0s 40us/sample - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 142/150\n",
      "577/577 [==============================] - 0s 40us/sample - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 143/150\n",
      "577/577 [==============================] - 0s 42us/sample - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 144/150\n",
      "577/577 [==============================] - 0s 41us/sample - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 145/150\n",
      "577/577 [==============================] - 0s 42us/sample - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 146/150\n",
      "577/577 [==============================] - 0s 42us/sample - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 147/150\n",
      "577/577 [==============================] - 0s 42us/sample - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 148/150\n",
      "577/577 [==============================] - 0s 38us/sample - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 149/150\n",
      "577/577 [==============================] - 0s 40us/sample - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 150/150\n",
      "577/577 [==============================] - 0s 44us/sample - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0134 - val_mse: 0.0134\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mse',optimizer='adam',metrics=['mse'])\n",
    "\n",
    "history = model.fit(X_train,y_train,epochs=150,batch_size=50,verbose=1,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'mse', 'val_loss', 'val_mse'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "# \"Loss\"\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
